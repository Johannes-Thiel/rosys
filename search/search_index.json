{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"basic_concepts/","text":"Basic Concepts \u00b6 World \u00b6 All state is stored in a data class called World . It not only contains the robots position, time, obstacles, etc but also images and other sensor data. This makes it easy to persist and restore the full state and simplifies the modularization of different Actors. Actors \u00b6 Actors encapsulate behaviour. Each should perform a specific task which they perform by reading and manipulating the world. For example: communication with a sensor, AI detection, monitoring battery level or similar. Actors can specify a frequency in which they want get called. Alternativly, Actors can be chained through follow_ups . These are helpful for example if one Actor fetches an image and another one should process it as soon as it's available. Automations \u00b6 RoSys provides an Actor called runtime.automator which receives instruction sequences. These Automations normally contains machine commands followed by conditions which can be awaited. For example there are alreay build-in automations like steering the robot along a spline.","title":"Basic Concepts"},{"location":"basic_concepts/#basic-concepts","text":"","title":"Basic Concepts"},{"location":"basic_concepts/#world","text":"All state is stored in a data class called World . It not only contains the robots position, time, obstacles, etc but also images and other sensor data. This makes it easy to persist and restore the full state and simplifies the modularization of different Actors.","title":"World"},{"location":"basic_concepts/#actors","text":"Actors encapsulate behaviour. Each should perform a specific task which they perform by reading and manipulating the world. For example: communication with a sensor, AI detection, monitoring battery level or similar. Actors can specify a frequency in which they want get called. Alternativly, Actors can be chained through follow_ups . These are helpful for example if one Actor fetches an image and another one should process it as soon as it's available.","title":"Actors"},{"location":"basic_concepts/#automations","text":"RoSys provides an Actor called runtime.automator which receives instruction sequences. These Automations normally contains machine commands followed by conditions which can be awaited. For example there are alreay build-in automations like steering the robot along a spline.","title":"Automations"},{"location":"development/","text":"Development \u00b6 Continuous Build \u00b6 We run our continous integration with GitHub Actions. For each commit the pytests are executed. Releases \u00b6 To release a new version create a new version on GitHub and describe the changes. A GitHub Action performs the following steps: If the pytests are successful a poetry build and deployment to pypi is issued. Also a multi-arch docker image is build and pushed to Docker Hub . Profiling \u00b6 In the system container run kernprof profiling.py to generate the profiling data. View it with the interactive tool python -m pstats profiling.py.prof","title":"Development"},{"location":"development/#development","text":"","title":"Development"},{"location":"development/#continuous-build","text":"We run our continous integration with GitHub Actions. For each commit the pytests are executed.","title":"Continuous Build"},{"location":"development/#releases","text":"To release a new version create a new version on GitHub and describe the changes. A GitHub Action performs the following steps: If the pytests are successful a poetry build and deployment to pypi is issued. Also a multi-arch docker image is build and pushed to Docker Hub .","title":"Releases"},{"location":"development/#profiling","text":"In the system container run kernprof profiling.py to generate the profiling data. View it with the interactive tool python -m pstats profiling.py.prof","title":"Profiling"},{"location":"features/","text":"RoSys - The Robot System \u00b6 RoSys provides an easy to use robot system. It's purpose is simlar to ROS . But RoSys is fully based on modern web technologies and focus on mobile robotics. See full documentation at https://rosys.io/ Features \u00b6 All Python Business logic is wired in Python while computation-heavy tasks are encapsulated through websockets or bindings. Shared State All code can access and manipulate a shared and typesafe state -- this does not mean it should. Good software design is still neccessary. But it is much easier to do if you do not have to perform serialization all the time. No Threading Thanks to asyncio you can write the business logic without locks and mutex mechanisms. The running system feels like everything is happening in parallel. But each code block is executed one after another through an event queue and yields execution as soon as it waits for I/O or heavy computation. Which is still executed in threads to not block the rest of the business logic. Web UI Most machines need some kind of human interaction. We made sure your robot can be operated fully off the grid with any web browser by incororporating NiceGUI . It's also possible to proxy the user interface through a gateway for remote operation. Simulation Robot hardware is often slower than your own computer. Therefore RoSys supports a simulation mode for rapid development. To get maximum performance the current implementation does not run a full physics engine. Testing You can use pytest to write high-level integration tests. It is based on the above-described simulation mode and accelerates the robot's time for super fast execution. Note Currently RoSys is mostly tested and developed on the Zauberzeug Robot Brain which uses Lizard for communication with motors, sensors and other peripherals. But the software architecture of RoSys also allows you to write your own actors if you prefer another industrial PC or setup.","title":"Features"},{"location":"features/#rosys-the-robot-system","text":"RoSys provides an easy to use robot system. It's purpose is simlar to ROS . But RoSys is fully based on modern web technologies and focus on mobile robotics. See full documentation at https://rosys.io/","title":"RoSys - The Robot System"},{"location":"features/#features","text":"All Python Business logic is wired in Python while computation-heavy tasks are encapsulated through websockets or bindings. Shared State All code can access and manipulate a shared and typesafe state -- this does not mean it should. Good software design is still neccessary. But it is much easier to do if you do not have to perform serialization all the time. No Threading Thanks to asyncio you can write the business logic without locks and mutex mechanisms. The running system feels like everything is happening in parallel. But each code block is executed one after another through an event queue and yields execution as soon as it waits for I/O or heavy computation. Which is still executed in threads to not block the rest of the business logic. Web UI Most machines need some kind of human interaction. We made sure your robot can be operated fully off the grid with any web browser by incororporating NiceGUI . It's also possible to proxy the user interface through a gateway for remote operation. Simulation Robot hardware is often slower than your own computer. Therefore RoSys supports a simulation mode for rapid development. To get maximum performance the current implementation does not run a full physics engine. Testing You can use pytest to write high-level integration tests. It is based on the above-described simulation mode and accelerates the robot's time for super fast execution. Note Currently RoSys is mostly tested and developed on the Zauberzeug Robot Brain which uses Lizard for communication with motors, sensors and other peripherals. But the software architecture of RoSys also allows you to write your own actors if you prefer another industrial PC or setup.","title":"Features"},{"location":"getting_started/","text":"Getting Started \u00b6 First install RoSys with pip or Docker. Then create a directory to host your code and put it under version control. Name your entry file main.py and add the following content: #!/usr/bin/env python3 from datetime import datetime from nicegui import ui from rosys import Runtime , World , Robot , Mode world = World ( mode = Mode . SIMULATION , robot = Robot ()) runtime = Runtime ( world ) status = ui . label () ui . timer ( 0.1 , lambda : status . set_text ( f ''' { datetime . utcfromtimestamp ( world . time ) } s''' )) ui . on_startup ( runtime . start ()) ui . on_shutdown ( runtime . stop ()) ui . run ( title = \"RoSys\" , port = 8080 ) If you launch the program, a webbrowser will open the url http://0.0.0.0:8080/ and show you the robots incrementing system time. Interaction \u00b6 Let's add a 3D view and jostick control to move the robot around: #!/usr/bin/env python3 from datetime import datetime from nicegui import ui from rosys import Runtime , World , Robot , Mode from rosys.ui import Joystick , RobotObject world = World ( mode = Mode . SIMULATION , robot = Robot ()) runtime = Runtime ( world ) status = ui . label () ui . timer ( 0.1 , lambda : status . set_text ( f ''' { datetime . utcfromtimestamp ( world . time ) } s''' )) Joystick ( size = 50 , color = 'blue' , steerer = runtime . steerer ) with ui . scene () as scene : robot = RobotObject ( world . robot ) ui . timer ( 0.05 , robot . update ) ui . on_startup ( runtime . start ()) ui . on_shutdown ( runtime . stop ()) ui . run ( title = \"RoSys\" , port = 8080 ) You can drive the robot by dragging the mouse inside the top left square:","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"First install RoSys with pip or Docker. Then create a directory to host your code and put it under version control. Name your entry file main.py and add the following content: #!/usr/bin/env python3 from datetime import datetime from nicegui import ui from rosys import Runtime , World , Robot , Mode world = World ( mode = Mode . SIMULATION , robot = Robot ()) runtime = Runtime ( world ) status = ui . label () ui . timer ( 0.1 , lambda : status . set_text ( f ''' { datetime . utcfromtimestamp ( world . time ) } s''' )) ui . on_startup ( runtime . start ()) ui . on_shutdown ( runtime . stop ()) ui . run ( title = \"RoSys\" , port = 8080 ) If you launch the program, a webbrowser will open the url http://0.0.0.0:8080/ and show you the robots incrementing system time.","title":"Getting Started"},{"location":"getting_started/#interaction","text":"Let's add a 3D view and jostick control to move the robot around: #!/usr/bin/env python3 from datetime import datetime from nicegui import ui from rosys import Runtime , World , Robot , Mode from rosys.ui import Joystick , RobotObject world = World ( mode = Mode . SIMULATION , robot = Robot ()) runtime = Runtime ( world ) status = ui . label () ui . timer ( 0.1 , lambda : status . set_text ( f ''' { datetime . utcfromtimestamp ( world . time ) } s''' )) Joystick ( size = 50 , color = 'blue' , steerer = runtime . steerer ) with ui . scene () as scene : robot = RobotObject ( world . robot ) ui . timer ( 0.05 , robot . update ) ui . on_startup ( runtime . start ()) ui . on_shutdown ( runtime . stop ()) ui . run ( title = \"RoSys\" , port = 8080 ) You can drive the robot by dragging the mouse inside the top left square:","title":"Interaction"},{"location":"installation/","text":"Installation \u00b6 On Your Desktop \u00b6 sudo apt-get install libcurl4-openssl-dev libssl-dev # required for pycurl python3 -m pip install rosys See Getting Started for what to do next. On The Robot \u00b6 While the above installation commands work in a well setup environment, it is often easier to run RoSys inside a docker container. Especially on NVidia Jetson devices with their old 18.04 LTS Ubuntu. Launching \u00b6 There are some specialities needed to start RoSys in different environments (Mac, Linux, Jetson, ...). To simplify the usage we wrapped this in a script called ./docker.sh which you can also use and adapt in your own project. Have a look at the examples to see how a setup of your own repo could look like. Hardware access \u00b6 You can configure the dockerized system by putting these variables into the /.env file: ESP_SERIAL=/dev/ttyTHS1 : path to the ESP device; default is /dev/null to be able to start RoSys anywhere ... Remote Development \u00b6 You can develop quite a lot of functionality with a simulated robot on your own computer. But there comes a time when you want to run your code on a real robot. Normally you will therefore start the container on the Robot Brain and connect via Wifi to the web interface. By using VS Code Remote Containers you can continue development as if you are using your own computer. Unfortunately robot hardware (for example NVidia Jetson) is much much slower than your own machine. With a large code base this can result in long restart times after you change some code (30 seconds or more). By launching sudo ./controller/esp_proxy.py on the Robot Brain you can keep developing on your computer while beeing connected to the hardware via WiFi. When the runtime is initalized it will first try to find the ESP32 of the Robot Brain locally. If this does not work, it tries to reach the Robot Brain via the local WiFi connection. Only if this also fails, it will fallback on a simulated hardware system.","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#on-your-desktop","text":"sudo apt-get install libcurl4-openssl-dev libssl-dev # required for pycurl python3 -m pip install rosys See Getting Started for what to do next.","title":"On Your Desktop"},{"location":"installation/#on-the-robot","text":"While the above installation commands work in a well setup environment, it is often easier to run RoSys inside a docker container. Especially on NVidia Jetson devices with their old 18.04 LTS Ubuntu.","title":"On The Robot"},{"location":"installation/#launching","text":"There are some specialities needed to start RoSys in different environments (Mac, Linux, Jetson, ...). To simplify the usage we wrapped this in a script called ./docker.sh which you can also use and adapt in your own project. Have a look at the examples to see how a setup of your own repo could look like.","title":"Launching"},{"location":"installation/#hardware-access","text":"You can configure the dockerized system by putting these variables into the /.env file: ESP_SERIAL=/dev/ttyTHS1 : path to the ESP device; default is /dev/null to be able to start RoSys anywhere ...","title":"Hardware access"},{"location":"installation/#remote-development","text":"You can develop quite a lot of functionality with a simulated robot on your own computer. But there comes a time when you want to run your code on a real robot. Normally you will therefore start the container on the Robot Brain and connect via Wifi to the web interface. By using VS Code Remote Containers you can continue development as if you are using your own computer. Unfortunately robot hardware (for example NVidia Jetson) is much much slower than your own machine. With a large code base this can result in long restart times after you change some code (30 seconds or more). By launching sudo ./controller/esp_proxy.py on the Robot Brain you can keep developing on your computer while beeing connected to the hardware via WiFi. When the runtime is initalized it will first try to find the ESP32 of the Robot Brain locally. If this does not work, it tries to reach the Robot Brain via the local WiFi connection. Only if this also fails, it will fallback on a simulated hardware system.","title":"Remote Development"},{"location":"safety/","text":"Safety \u00b6 Python is fast enough for most highlevel logic. But of course it has no realtime guarantees. Safety relevant behaviour should therefore be written in Lizard and executed on a suitable microprocessor. The microprocessor governs the hardware of the robot and must be able to perform safety actions like triggering emergency hold etc. We suggest you use an industrial PC like the Zauberzeug Robot Brain . It provides an Linux system with AI acceleration to run RoSys, an integrated ESP32 to run Lizard and six I/O sockets for CAN, RS484, SPI, I2C ... with a software controllable ENABLE switch. Operation States \u00b6 on \u00b6 This is the default state after launching RoSys. To enter the next state \"manual.drive\" you should write an Automation which ensures the robot is ready (eg. no active emergency stops). manual.drive \u00b6 Normally this is the default target after \"on\". All axis should not be moved. Except the drive units. The purpose of this state is to steer the robot by an operator. homing \u00b6 To transition to higher level operation states like \"manual.operate\" or \"auto\" the robot requires to know the zero positions of each motor axis. Normally homing is done sequencially on a per axis basis. manual.operate \u00b6 Mostly used during development but also sometimes for maintainance. All axis can be controlled by the operator as long as the movement does not violate safety requirements. It can only be activated if homing was sucessful. auto \u00b6 This state indicates the fully autonomous operation of the robot. Activation must happen through a users interaction and requires an successful homing. hold \u00b6 In this state the robot must completely stop as quick as possible. For example by applying the breaks. This state is entered if any safety requirement is violated. stop \u00b6 Cuts all power connections leading to a total emidate shutdown which must be reactivated manually. Most robots do not require this state.","title":"Safety"},{"location":"safety/#safety","text":"Python is fast enough for most highlevel logic. But of course it has no realtime guarantees. Safety relevant behaviour should therefore be written in Lizard and executed on a suitable microprocessor. The microprocessor governs the hardware of the robot and must be able to perform safety actions like triggering emergency hold etc. We suggest you use an industrial PC like the Zauberzeug Robot Brain . It provides an Linux system with AI acceleration to run RoSys, an integrated ESP32 to run Lizard and six I/O sockets for CAN, RS484, SPI, I2C ... with a software controllable ENABLE switch.","title":"Safety"},{"location":"safety/#operation-states","text":"","title":"Operation States"},{"location":"safety/#on","text":"This is the default state after launching RoSys. To enter the next state \"manual.drive\" you should write an Automation which ensures the robot is ready (eg. no active emergency stops).","title":"on"},{"location":"safety/#manualdrive","text":"Normally this is the default target after \"on\". All axis should not be moved. Except the drive units. The purpose of this state is to steer the robot by an operator.","title":"manual.drive"},{"location":"safety/#homing","text":"To transition to higher level operation states like \"manual.operate\" or \"auto\" the robot requires to know the zero positions of each motor axis. Normally homing is done sequencially on a per axis basis.","title":"homing"},{"location":"safety/#manualoperate","text":"Mostly used during development but also sometimes for maintainance. All axis can be controlled by the operator as long as the movement does not violate safety requirements. It can only be activated if homing was sucessful.","title":"manual.operate"},{"location":"safety/#auto","text":"This state indicates the fully autonomous operation of the robot. Activation must happen through a users interaction and requires an successful homing.","title":"auto"},{"location":"safety/#hold","text":"In this state the robot must completely stop as quick as possible. For example by applying the breaks. This state is entered if any safety requirement is violated.","title":"hold"},{"location":"safety/#stop","text":"Cuts all power connections leading to a total emidate shutdown which must be reactivated manually. Most robots do not require this state.","title":"stop"},{"location":"user_interface/","text":"User Interface \u00b6 RoSys plays very well with NiceGUI and provides aditional robot-related components through the rosys.ui package. NiceGUI is a high-level web UI framework on top of JustPy . This means you can write all UI code in Python. The state is automatically reflected in the browser through websockets. If required RoSys can also be used with other user interfaces or interaction models. For example a completely App based contol through Bluetooth LE with Flutter.","title":"User Interface"},{"location":"user_interface/#user-interface","text":"RoSys plays very well with NiceGUI and provides aditional robot-related components through the rosys.ui package. NiceGUI is a high-level web UI framework on top of JustPy . This means you can write all UI code in Python. The state is automatically reflected in the browser through websockets. If required RoSys can also be used with other user interfaces or interaction models. For example a completely App based contol through Bluetooth LE with Flutter.","title":"User Interface"}]}